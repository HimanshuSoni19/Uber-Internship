{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1de71e",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3288cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              DateTime  Junction  Vehicles           ID            date_time  \\\n",
      "0  2015-01-11 00:00:00         1        15  20151101001  2009-01-11 00:00:00   \n",
      "1  2015-01-11 00:00:00         1        15  20151101001  2010-01-11 00:00:00   \n",
      "2  2015-01-11 00:00:00         1        15  20151101001  2011-01-11 00:00:00   \n",
      "3  2015-01-11 00:00:00         1        15  20151101001  2012-01-11 00:00:00   \n",
      "4  2015-01-11 00:00:00         1        15  20151101001  2013-01-11 00:00:00   \n",
      "\n",
      "   maxtempC  mintempC  totalSnow_cm  sunHour  uvIndex  ...  precipMM  \\\n",
      "0      27.0      15.0           0.0     11.6      6.0  ...       0.0   \n",
      "1      26.0      17.0           0.0     11.6      5.0  ...       0.0   \n",
      "2      28.0      14.0           0.0     11.6      5.0  ...       0.0   \n",
      "3      29.0      17.0           0.0     11.6      5.0  ...       0.0   \n",
      "4      29.0      16.0           0.0     11.6      6.0  ...       0.0   \n",
      "\n",
      "   pressure     tempC visibility winddirDegree windspeedKmph  date  day  \\\n",
      "0    1016.0 -1.250127       10.0         100.0     -0.654230   NaN  NaN   \n",
      "1    1015.0 -0.637934        2.0         130.0     -1.136464   NaN  NaN   \n",
      "2    1012.0 -1.862320       10.0          32.0     -0.895347   NaN  NaN   \n",
      "3    1014.0 -0.637934       10.0         193.0     -1.859814   NaN  NaN   \n",
      "4    1014.0 -1.250127       10.0          93.0     -0.171996   NaN  NaN   \n",
      "\n",
      "   holiday  holiday_type  \n",
      "0      NaN           NaN  \n",
      "1      NaN           NaN  \n",
      "2      NaN           NaN  \n",
      "3      NaN           NaN  \n",
      "4      NaN           NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Loading the combined dataset\n",
    "combined_data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1101f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92040 entries, 0 to 92039\n",
      "Data columns (total 33 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DateTime           92040 non-null  datetime64[ns]\n",
      " 1   Junction           92040 non-null  int64         \n",
      " 2   Vehicles           92040 non-null  int64         \n",
      " 3   ID                 92040 non-null  int64         \n",
      " 4   date_time          92040 non-null  datetime64[ns]\n",
      " 5   maxtempC           92040 non-null  float64       \n",
      " 6   mintempC           92040 non-null  float64       \n",
      " 7   totalSnow_cm       92040 non-null  float64       \n",
      " 8   sunHour            92040 non-null  float64       \n",
      " 9   uvIndex            92040 non-null  float64       \n",
      " 10  uvIndex.1          92040 non-null  float64       \n",
      " 11  moon_illumination  92040 non-null  float64       \n",
      " 12  moonrise           92040 non-null  object        \n",
      " 13  moonset            92040 non-null  object        \n",
      " 14  sunrise            92040 non-null  object        \n",
      " 15  sunset             92040 non-null  object        \n",
      " 16  DewPointC          92040 non-null  float64       \n",
      " 17  FeelsLikeC         92040 non-null  float64       \n",
      " 18  HeatIndexC         92040 non-null  float64       \n",
      " 19  WindChillC         92040 non-null  float64       \n",
      " 20  WindGustKmph       92040 non-null  float64       \n",
      " 21  cloudcover         92040 non-null  float64       \n",
      " 22  humidity           92040 non-null  float64       \n",
      " 23  precipMM           92040 non-null  float64       \n",
      " 24  pressure           92040 non-null  float64       \n",
      " 25  tempC              92040 non-null  float64       \n",
      " 26  visibility         92040 non-null  float64       \n",
      " 27  winddirDegree      92040 non-null  float64       \n",
      " 28  windspeedKmph      92040 non-null  float64       \n",
      " 29  date               88872 non-null  object        \n",
      " 30  day                88872 non-null  object        \n",
      " 31  holiday            88872 non-null  object        \n",
      " 32  holiday_type       88872 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(20), int64(3), object(8)\n",
      "memory usage: 23.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Convert date columns to datetime\n",
    "combined_data['DateTime'] = pd.to_datetime(combined_data['DateTime'])\n",
    "combined_data['date_time'] = pd.to_datetime(combined_data['date_time'])\n",
    "print(combined_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec027a",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49553759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime                0\n",
      "Junction                0\n",
      "Vehicles                0\n",
      "ID                      0\n",
      "date_time               0\n",
      "maxtempC                0\n",
      "mintempC                0\n",
      "totalSnow_cm            0\n",
      "sunHour                 0\n",
      "uvIndex                 0\n",
      "uvIndex.1               0\n",
      "moon_illumination       0\n",
      "moonrise                0\n",
      "moonset                 0\n",
      "sunrise                 0\n",
      "sunset                  0\n",
      "DewPointC               0\n",
      "FeelsLikeC              0\n",
      "HeatIndexC              0\n",
      "WindChillC              0\n",
      "WindGustKmph            0\n",
      "cloudcover              0\n",
      "humidity                0\n",
      "precipMM                0\n",
      "pressure                0\n",
      "tempC                   0\n",
      "visibility              0\n",
      "winddirDegree           0\n",
      "windspeedKmph           0\n",
      "date                 3168\n",
      "day                  3168\n",
      "holiday              3168\n",
      "holiday_type         3168\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data (assuming it's a DataFrame named df)\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = combined_data.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e739dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12136\\3045488514.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  combined_data.fillna(combined_data.mean(), inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12136\\3045488514.py:6: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  combined_data.fillna(combined_data.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with a high percentage of missing values\n",
    "combined_data.drop(columns=['date', 'day', 'holiday', 'holiday_type'], inplace=True)\n",
    "\n",
    "# Check for any remaining missing values and handle them\n",
    "# (If there are any remaining missing values in important columns, decide on an imputation strategy)\n",
    "combined_data.fillna(combined_data.mean(), inplace=True)\n",
    "\n",
    "# Step 3: Drop irrelevant columns\n",
    "combined_data.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758c7117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DateTime  Junction  Vehicles  date_time  maxtempC  mintempC  totalSnow_cm  \\\n",
      "0 2015-01-11         1        15 2009-01-11      27.0      15.0           0.0   \n",
      "1 2015-01-11         1        15 2010-01-11      26.0      17.0           0.0   \n",
      "2 2015-01-11         1        15 2011-01-11      28.0      14.0           0.0   \n",
      "3 2015-01-11         1        15 2012-01-11      29.0      17.0           0.0   \n",
      "4 2015-01-11         1        15 2013-01-11      29.0      16.0           0.0   \n",
      "\n",
      "   sunHour  uvIndex  uvIndex.1  ...  WindChillC WindGustKmph cloudcover  \\\n",
      "0     11.6      6.0        1.0  ...        17.0         19.0        8.0   \n",
      "1     11.6      5.0        1.0  ...        19.0         15.0       52.0   \n",
      "2     11.6      5.0        1.0  ...        17.0         22.0        0.0   \n",
      "3     11.6      5.0        1.0  ...        19.0         10.0       65.0   \n",
      "4     11.6      6.0        1.0  ...        17.0         22.0        9.0   \n",
      "\n",
      "   humidity precipMM  pressure     tempC  visibility  winddirDegree  \\\n",
      "0  0.375282      0.0    1016.0 -1.250127        10.0          100.0   \n",
      "1  1.003753      0.0    1015.0 -0.637934         2.0          130.0   \n",
      "2 -1.053061      0.0    1012.0 -1.862320        10.0           32.0   \n",
      "3  0.146747      0.0    1014.0 -0.637934        10.0          193.0   \n",
      "4  0.489549      0.0    1014.0 -1.250127        10.0           93.0   \n",
      "\n",
      "   windspeedKmph  \n",
      "0      -0.654230  \n",
      "1      -1.136464  \n",
      "2      -0.895347  \n",
      "3      -1.859814  \n",
      "4      -0.171996  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cfff02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "numerical_features = ['Vehicles', 'maxtempC', 'mintempC', 'totalSnow_cm', 'sunHour', 'uvIndex', 'moon_illumination', \n",
    "                      'DewPointC', 'FeelsLikeC', 'HeatIndexC', 'WindChillC', 'WindGustKmph', 'cloudcover', 'humidity', \n",
    "                      'precipMM', 'pressure', 'tempC', 'visibility', 'winddirDegree', 'windspeedKmph']\n",
    "scaler = StandardScaler()\n",
    "combined_data[numerical_features] = scaler.fit_transform(combined_data[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e28320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DateTime  Junction  Vehicles  date_time  maxtempC  mintempC  totalSnow_cm  \\\n",
      "0 2015-01-11         1  -0.14097 2009-01-11  0.219491 -1.564123           0.0   \n",
      "1 2015-01-11         1  -0.14097 2010-01-11 -0.177560 -0.616582           0.0   \n",
      "2 2015-01-11         1  -0.14097 2011-01-11  0.616543 -2.037894           0.0   \n",
      "3 2015-01-11         1  -0.14097 2012-01-11  1.013594 -0.616582           0.0   \n",
      "4 2015-01-11         1  -0.14097 2013-01-11  1.013594 -1.090352           0.0   \n",
      "\n",
      "    sunHour   uvIndex  uvIndex.1  ...  WindChillC WindGustKmph cloudcover  \\\n",
      "0  0.586658  1.165652        1.0  ...   -1.304933     0.030593  -1.529921   \n",
      "1  0.586658 -0.417307        1.0  ...   -0.702150    -0.749465   0.367961   \n",
      "2  0.586658 -0.417307        1.0  ...   -1.304933     0.615638  -1.874991   \n",
      "3  0.586658 -0.417307        1.0  ...   -0.702150    -1.724539   0.928699   \n",
      "4  0.586658  1.165652        1.0  ...   -1.304933     0.615638  -1.486788   \n",
      "\n",
      "   humidity  precipMM  pressure     tempC  visibility  winddirDegree  \\\n",
      "0  0.375282 -0.132504  0.961635 -1.250127    0.287257      -0.292659   \n",
      "1  1.003753 -0.132504  0.561046 -0.637934   -3.634233       0.216640   \n",
      "2 -1.053061 -0.132504 -0.640720 -1.862320    0.287257      -1.447072   \n",
      "3  0.146747 -0.132504  0.160458 -0.637934    0.287257       1.286170   \n",
      "4  0.489549 -0.132504  0.160458 -1.250127    0.287257      -0.411496   \n",
      "\n",
      "   windspeedKmph  \n",
      "0      -0.654230  \n",
      "1      -1.136464  \n",
      "2      -0.895347  \n",
      "3      -1.859814  \n",
      "4      -0.171996  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92040 entries, 0 to 92039\n",
      "Data columns (total 28 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DateTime           92040 non-null  datetime64[ns]\n",
      " 1   Junction           92040 non-null  int64         \n",
      " 2   Vehicles           92040 non-null  float64       \n",
      " 3   date_time          92040 non-null  datetime64[ns]\n",
      " 4   maxtempC           92040 non-null  float64       \n",
      " 5   mintempC           92040 non-null  float64       \n",
      " 6   totalSnow_cm       92040 non-null  float64       \n",
      " 7   sunHour            92040 non-null  float64       \n",
      " 8   uvIndex            92040 non-null  float64       \n",
      " 9   uvIndex.1          92040 non-null  float64       \n",
      " 10  moon_illumination  92040 non-null  float64       \n",
      " 11  moonrise           92040 non-null  object        \n",
      " 12  moonset            92040 non-null  object        \n",
      " 13  sunrise            92040 non-null  object        \n",
      " 14  sunset             92040 non-null  object        \n",
      " 15  DewPointC          92040 non-null  float64       \n",
      " 16  FeelsLikeC         92040 non-null  float64       \n",
      " 17  HeatIndexC         92040 non-null  float64       \n",
      " 18  WindChillC         92040 non-null  float64       \n",
      " 19  WindGustKmph       92040 non-null  float64       \n",
      " 20  cloudcover         92040 non-null  float64       \n",
      " 21  humidity           92040 non-null  float64       \n",
      " 22  precipMM           92040 non-null  float64       \n",
      " 23  pressure           92040 non-null  float64       \n",
      " 24  tempC              92040 non-null  float64       \n",
      " 25  visibility         92040 non-null  float64       \n",
      " 26  winddirDegree      92040 non-null  float64       \n",
      " 27  windspeedKmph      92040 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(21), int64(1), object(4)\n",
      "memory usage: 19.7+ MB\n",
      "None\n",
      "           Junction      Vehicles      maxtempC      mintempC  totalSnow_cm  \\\n",
      "count  92040.000000  9.204000e+04  9.204000e+04  9.204000e+04       92040.0   \n",
      "mean       2.094394 -7.411137e-18  3.705568e-16  5.681872e-16           0.0   \n",
      "std        0.902822  1.000005e+00  1.000005e+00  1.000005e+00           0.0   \n",
      "min        1.000000 -9.605398e-01 -3.353972e+00 -3.459206e+00           0.0   \n",
      "25%        1.000000 -6.092957e-01 -5.746117e-01 -1.428107e-01           0.0   \n",
      "50%        2.000000 -3.165923e-01 -5.746117e-01  3.309601e-01           0.0   \n",
      "75%        3.000000  2.688146e-01  6.165428e-01  3.309601e-01           0.0   \n",
      "max        4.000000  9.518243e+00  5.381161e+00  4.121127e+00           0.0   \n",
      "\n",
      "            sunHour       uvIndex     uvIndex.1  moon_illumination  \\\n",
      "count  9.204000e+04  9.204000e+04  92040.000000       9.204000e+04   \n",
      "mean   2.322156e-16 -4.002014e-16      2.476760      -1.828080e-16   \n",
      "std    1.000005e+00  1.000005e+00      2.394783       1.000005e+00   \n",
      "min   -3.316009e+00 -2.000265e+00      1.000000      -1.472299e+00   \n",
      "25%   -9.427653e-01 -4.173066e-01      1.000000      -4.234593e-01   \n",
      "50%    5.866584e-01 -4.173066e-01      1.000000      -4.234593e-01   \n",
      "75%    5.866584e-01 -4.173066e-01      5.000000       4.640202e-01   \n",
      "max    1.272262e+00  4.331568e+00     10.000000       2.561699e+00   \n",
      "\n",
      "          DewPointC  ...    WindChillC  WindGustKmph    cloudcover  \\\n",
      "count  9.204000e+04  ...  9.204000e+04  9.204000e+04  9.204000e+04   \n",
      "mean   3.507938e-16  ...  4.594905e-16 -5.434834e-17 -1.482227e-16   \n",
      "std    1.000005e+00  ...  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -6.217599e+00  ... -2.811892e+00 -3.479671e+00 -1.874991e+00   \n",
      "25%   -2.861767e-01  ... -4.007585e-01 -5.544507e-01 -7.103814e-01   \n",
      "50%    4.116377e-01  ... -4.007585e-01  4.206228e-01  3.679607e-01   \n",
      "75%    4.116377e-01  ...  2.020247e-01  4.206228e-01  3.679607e-01   \n",
      "max    2.853988e+00  ...  6.229857e+00  5.491005e+00  2.438378e+00   \n",
      "\n",
      "           humidity      precipMM      pressure         tempC    visibility  \\\n",
      "count  9.204000e+04  9.204000e+04  9.204000e+04  9.204000e+04  9.204000e+04   \n",
      "mean   9.387440e-17 -1.235189e-17 -6.862713e-15 -8.893364e-17 -9.634478e-17   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -3.738347e+00 -1.325041e-01 -4.646610e+00 -3.086707e+00 -4.614605e+00   \n",
      "25%   -4.245904e-01 -1.325041e-01 -2.401314e-01 -3.318374e-01  2.872575e-01   \n",
      "50%    5.466830e-01 -1.325041e-01  5.610465e-01 -3.318374e-01  2.872575e-01   \n",
      "75%    5.466830e-01 -1.325041e-01  5.610465e-01  2.803557e-01  2.872575e-01   \n",
      "max    1.232288e+00  3.734488e+01  2.964580e+00  5.790094e+00  5.189120e+00   \n",
      "\n",
      "       winddirDegree  windspeedKmph  \n",
      "count   9.204000e+04   92040.000000  \n",
      "mean   -5.064277e-17       0.000000  \n",
      "std     1.000005e+00       1.000005  \n",
      "min    -1.990325e+00      -3.306516  \n",
      "25%    -4.284724e-01      -0.654230  \n",
      "50%    -1.059160e-01       0.551355  \n",
      "75%    -1.059160e-01       0.551355  \n",
      "max     4.121271e+00       6.097043  \n",
      "\n",
      "[8 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verifying data cleaning\n",
    "print(combined_data.head())\n",
    "print(combined_data.info())\n",
    "print(combined_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12920d11",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9ff6120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DateTime  Junction  Vehicles  date_time  maxtempC  mintempC  totalSnow_cm  \\\n",
      "3 2015-01-11         1  -0.14097 2012-01-11  1.013594 -0.616582           0.0   \n",
      "4 2015-01-11         1  -0.14097 2013-01-11  1.013594 -1.090352           0.0   \n",
      "5 2015-01-11         1  -0.14097 2014-01-11  0.616543 -1.564123           0.0   \n",
      "6 2015-01-11         1  -0.14097 2015-01-11 -0.177560 -2.985436           0.0   \n",
      "7 2015-01-11         1  -0.14097 2016-01-11  0.219491 -2.037894           0.0   \n",
      "\n",
      "    sunHour   uvIndex  uvIndex.1  ...  winddirDegree windspeedKmph hour day  \\\n",
      "3  0.586658 -0.417307        1.0  ...       1.286170     -1.859814    0  11   \n",
      "4  0.586658  1.165652        1.0  ...      -0.411496     -0.171996    0  11   \n",
      "5  0.586658  1.165652        1.0  ...      -0.156846     -0.413113    0  11   \n",
      "6  0.586658 -0.417307        1.0  ...      -1.090562     -0.654230    0  11   \n",
      "7  0.586658 -0.417307        1.0  ...      -0.377542     -0.413113    0  11   \n",
      "\n",
      "  month  day_of_week  is_weekend    lag_1    lag_2    lag_3  \n",
      "3     1            6           1 -0.14097 -0.14097 -0.14097  \n",
      "4     1            6           1 -0.14097 -0.14097 -0.14097  \n",
      "5     1            6           1 -0.14097 -0.14097 -0.14097  \n",
      "6     1            6           1 -0.14097 -0.14097 -0.14097  \n",
      "7     1            6           1 -0.14097 -0.14097 -0.14097  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92037 entries, 3 to 92039\n",
      "Data columns (total 36 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DateTime           92037 non-null  datetime64[ns]\n",
      " 1   Junction           92037 non-null  int64         \n",
      " 2   Vehicles           92037 non-null  float64       \n",
      " 3   date_time          92037 non-null  datetime64[ns]\n",
      " 4   maxtempC           92037 non-null  float64       \n",
      " 5   mintempC           92037 non-null  float64       \n",
      " 6   totalSnow_cm       92037 non-null  float64       \n",
      " 7   sunHour            92037 non-null  float64       \n",
      " 8   uvIndex            92037 non-null  float64       \n",
      " 9   uvIndex.1          92037 non-null  float64       \n",
      " 10  moon_illumination  92037 non-null  float64       \n",
      " 11  moonrise           92037 non-null  object        \n",
      " 12  moonset            92037 non-null  object        \n",
      " 13  sunrise            92037 non-null  object        \n",
      " 14  sunset             92037 non-null  object        \n",
      " 15  DewPointC          92037 non-null  float64       \n",
      " 16  FeelsLikeC         92037 non-null  float64       \n",
      " 17  HeatIndexC         92037 non-null  float64       \n",
      " 18  WindChillC         92037 non-null  float64       \n",
      " 19  WindGustKmph       92037 non-null  float64       \n",
      " 20  cloudcover         92037 non-null  float64       \n",
      " 21  humidity           92037 non-null  float64       \n",
      " 22  precipMM           92037 non-null  float64       \n",
      " 23  pressure           92037 non-null  float64       \n",
      " 24  tempC              92037 non-null  float64       \n",
      " 25  visibility         92037 non-null  float64       \n",
      " 26  winddirDegree      92037 non-null  float64       \n",
      " 27  windspeedKmph      92037 non-null  float64       \n",
      " 28  hour               92037 non-null  int64         \n",
      " 29  day                92037 non-null  int64         \n",
      " 30  month              92037 non-null  int64         \n",
      " 31  day_of_week        92037 non-null  int64         \n",
      " 32  is_weekend         92037 non-null  int32         \n",
      " 33  lag_1              92037 non-null  float64       \n",
      " 34  lag_2              92037 non-null  float64       \n",
      " 35  lag_3              92037 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(24), int32(1), int64(5), object(4)\n",
      "memory usage: 25.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create time-based features\n",
    "combined_data['hour'] = combined_data['DateTime'].dt.hour\n",
    "combined_data['day'] = combined_data['DateTime'].dt.day\n",
    "combined_data['month'] = combined_data['DateTime'].dt.month\n",
    "combined_data['day_of_week'] = combined_data['DateTime'].dt.dayofweek\n",
    "combined_data['is_weekend'] = combined_data['day_of_week'].isin([5, 6]).astype(int)  # 5: Saturday, 6: Sunday\n",
    "\n",
    "# Create lag features\n",
    "combined_data['lag_1'] = combined_data['Vehicles'].shift(1)\n",
    "combined_data['lag_2'] = combined_data['Vehicles'].shift(2)\n",
    "combined_data['lag_3'] = combined_data['Vehicles'].shift(3)\n",
    "\n",
    "# Drop rows with NaN values created by lag features\n",
    "combined_data.dropna(inplace=True)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(combined_data.head())\n",
    "print(combined_data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df168c",
   "metadata": {},
   "source": [
    "# Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "511d45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (15342, 29)\n",
      "Validation data shape: (15339, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Define features and target\n",
    "features = combined_data.drop(columns=['DateTime', 'Vehicles', 'date_time', 'moonrise', 'moonset', 'sunrise', 'sunset'])\n",
    "target = combined_data['Vehicles']\n",
    "\n",
    "# Time-based splitting\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Loop over splits\n",
    "for train_index, val_index in tscv.split(features):\n",
    "    X_train, X_val = features.iloc[train_index], features.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "\n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Validation data shape: {X_val.shape}\")\n",
    "\n",
    "    break  # Remove this break after verifying the split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7bc8d",
   "metadata": {},
   "source": [
    "# ARIMA Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "824e987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data.sort_values(by='DateTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57599832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12136\\3797462393.py:2: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  combined_data = combined_data.asfreq('D')  # or 'H' for hourly, as per your data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m combined_data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39masfreq(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11367\u001b[0m, in \u001b[0;36mDataFrame.asfreq\u001b[1;34m(self, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[0;32m  11358\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39masfreq, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_shared_doc_kwargs)\n\u001b[0;32m  11359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masfreq\u001b[39m(\n\u001b[0;32m  11360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11365\u001b[0m     fill_value: Hashable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  11366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m> 11367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39masfreq(\n\u001b[0;32m  11368\u001b[0m         freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[0;32m  11369\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m  11370\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  11371\u001b[0m         normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m  11372\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m  11373\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:8235\u001b[0m, in \u001b[0;36mNDFrame.asfreq\u001b[1;34m(self, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[0;32m   8128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   8129\u001b[0m \u001b[38;5;124;03mConvert time series to specified frequency.\u001b[39;00m\n\u001b[0;32m   8130\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8231\u001b[0m \u001b[38;5;124;03m2000-01-01 00:03:00    3.0\u001b[39;00m\n\u001b[0;32m   8232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   8233\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asfreq\n\u001b[1;32m-> 8235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m asfreq(\n\u001b[0;32m   8236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8237\u001b[0m     freq,\n\u001b[0;32m   8238\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   8239\u001b[0m     how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m   8240\u001b[0m     normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m   8241\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   8242\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:2231\u001b[0m, in \u001b[0;36masfreq\u001b[1;34m(obj, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[0;32m   2229\u001b[0m dti \u001b[38;5;241m=\u001b[39m date_range(obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin(), obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax(), freq\u001b[38;5;241m=\u001b[39mfreq)\n\u001b[0;32m   2230\u001b[0m dti\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m-> 2231\u001b[0m new_obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mreindex(dti, method\u001b[38;5;241m=\u001b[39mmethod, fill_value\u001b[38;5;241m=\u001b[39mfill_value)\n\u001b[0;32m   2232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m   2233\u001b[0m     new_obj\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m new_obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnormalize()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:347\u001b[0m, in \u001b[0;36mrewrite_axis_style_signature.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5205\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5203\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   5204\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 5205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5288\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[0;32m   5290\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   5291\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5004\u001b[0m, in \u001b[0;36mDataFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5002\u001b[0m index \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   5003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5004\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39m_reindex_index(\n\u001b[0;32m   5005\u001b[0m         index, method, copy, level, fill_value, limit, tolerance\n\u001b[0;32m   5006\u001b[0m     )\n\u001b[0;32m   5008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frame\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5023\u001b[0m, in \u001b[0;36mDataFrame._reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reindex_index\u001b[39m(\n\u001b[0;32m   5011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5012\u001b[0m     new_index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5018\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5019\u001b[0m ):\n\u001b[0;32m   5020\u001b[0m     new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5021\u001b[0m         new_index, method\u001b[38;5;241m=\u001b[39mmethod, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   5022\u001b[0m     )\n\u001b[1;32m-> 5023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5024\u001b[0m         {\u001b[38;5;241m0\u001b[39m: [new_index, indexer]},\n\u001b[0;32m   5025\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5026\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5027\u001b[0m         allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5028\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5355\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   5352\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m   5354\u001b[0m \u001b[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[1;32m-> 5355\u001b[0m new_data \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m   5356\u001b[0m     index,\n\u001b[0;32m   5357\u001b[0m     indexer,\n\u001b[0;32m   5358\u001b[0m     axis\u001b[38;5;241m=\u001b[39mbaxis,\n\u001b[0;32m   5359\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5360\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39mallow_dups,\n\u001b[0;32m   5361\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5362\u001b[0m )\n\u001b[0;32m   5363\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   5364\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:737\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[1;32m--> 737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39m_validate_can_reindex(indexer)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4316\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 4316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "combined_data.set_index('DateTime', inplace=True)\n",
    "combined_data = combined_data.asfreq('D')  # or 'H' for hourly, as per your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e06943a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['DateTime'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure data is sorted and set frequency\u001b[39;00m\n\u001b[0;32m      5\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m combined_data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39masfreq(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assuming daily frequency, adjust if needed\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define features and target for ARIMA\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6012\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6009\u001b[0m                 missing\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m   6011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 6012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are in the columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   6015\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['DateTime'] are in the columns\""
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Ensure data is sorted and set frequency\n",
    "combined_data = combined_data.sort_values(by='DateTime')\n",
    "combined_data.set_index('DateTime', inplace=True)\n",
    "combined_data = combined_data.asfreq('D')  # Assuming daily frequency, adjust if needed\n",
    "\n",
    "# Define features and target for ARIMA\n",
    "train = combined_data.loc[:'2021-12-31', 'Vehicles']  # Example split, adjust as needed\n",
    "test = combined_data.loc['2022-01-01:', 'Vehicles']\n",
    "\n",
    "# Train ARIMA model\n",
    "arima_model = ARIMA(train, order=(5, 1, 0))  # Example order, adjust based on model selection\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Make predictions\n",
    "arima_predictions = arima_model_fit.forecast(steps=len(test))\n",
    "arima_mse = mean_squared_error(test, arima_predictions)\n",
    "print(f\"ARIMA Model MSE: {arima_mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339029f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432a402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906c3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4257c839",
   "metadata": {},
   "source": [
    "# Training the Gradient Boosting Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "247c1b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor MSE: 1.155235206746355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Train the model on the training data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "predictions = gbr.predict(X_val)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_val, predictions)\n",
    "\n",
    "print(f\"Gradient Boosting Regressor MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b79b2",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd66af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
